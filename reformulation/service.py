"""
Service de reformulation utilisant 2 IA en parall√®le (Gemini + DeepSeek)
"""
import os
import json
import time
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional
from bs4 import BeautifulSoup
import re
import httpx
from google import generativeai as genai

logger = logging.getLogger(__name__)

# Configuration
BASE_DIR = Path(__file__).parent
PROMPTS_DIR = BASE_DIR / "prompts_section"
TEMPERATURE = 0.1
API_DELAY = 0.5

# Liste des 34 sections
SECTIONS = [
    "informations-generales",
    "periode-essai",
    "delai-prevenance",
    "preavis",
    "indemnite-licenciement",
    "indemnite-depart-retraite",
    "indemnite-mise-retraite",
    "indemnite-rupture-conventionnelle",
    "indemnite-precarite",
    "classification",
    "grille-remuneration",
    "durees-travail",
    "heures-supplementaires",
    "majoration-nuit",
    "majoration-dimanche",
    "majoration-ferie",
    "temps-partiel",
    "forfait-jours",
    "amenagement-temps-travail",
    "conges-payes",
    "evenements-familiaux",
    "maladie",
    "maternite-paternite",
    "accident-travail",
    "cet",
    "apprenti",
    "stagiaire",
    "contrat-professionnalisation",
    "cotisation-retraite",
    "cotisation-prevoyance",
    "cotisation-mutuelle",
    "paritarisme-financement",
    "contributions-formation",
    "primes-indemnites-avantages",
]

# System Prompt
SYSTEM_PROMPT = """
Tu es un assistant sp√©cialis√© dans l'extraction et la restructuration de donn√©es issues de conventions collectives fran√ßaises. Ces donn√©es sont destin√©es √† √™tre int√©gr√©es dans un logiciel de paie.

## ‚ö†Ô∏è R√àGLE ABSOLUE : NE RIEN OMETTRE

La source fournie est **d√©j√† une synth√®se**. Ton r√¥le n'est PAS d'analyser, trier ou s√©lectionner.

### Tu dois :
- ‚úÖ **TOUT prendre** ‚Äî chaque information, chaque nuance, chaque cas particulier
- ‚úÖ **R√©organiser** dans la structure JSON demand√©e
- ‚úÖ **Reformuler** si n√©cessaire pour clarifier
- ‚úÖ **Conserver** toutes les valeurs, tous les seuils, toutes les conditions

### Tu ne dois PAS :
- ‚ùå D√©cider qu'une information est "moins importante"
- ‚ùå R√©sumer ou simplifier des r√®gles complexes
- ‚ùå Omettre des cas particuliers, r√©gionaux ou cat√©goriels
- ‚ùå Fusionner des tranches ou des seuils diff√©rents
- ‚ùå Appliquer le Code du travail si la convention est muette
- ‚ùå Inventer des informations qui ne sont pas dans la source

**Si c'est dans la source, c'est dans le JSON. Point final.**

## ÔøΩ FORMAT DE SORTIE

### OBLIGATOIRE :
- R√©ponds **uniquement** avec un objet JSON valide
- **Aucun texte** avant le JSON
- **Aucun texte** apr√®s le JSON
- **Aucun bloc markdown** (pas de ```json```)
- Juste l'objet JSON brut

## üìä TABLEAUX vs LISTES

### Format tableau :
```json
"tableau": {
  "colonnes": ["En-t√™te 1", "En-t√™te 2"],
  "lignes": [
    ["Valeur 1a", "Valeur 1b"],
    ["Valeur 2a *", "Valeur 2b"]
  ]
}
```

## ‚ú≥Ô∏è SYST√àME D'AST√âRISQUES

Pour les cas particuliers dans les tableaux :
- Dans la cellule : `"2 mois *"` ou `"3 mois **"`
- Dans pr√©cisions : `"* Explication..."`, `"** Autre explication..."`

## ‚ö†Ô∏è VALEURS NULLES

- Information absente de la source ‚Üí `null`
- Cat√©gorie sans √©l√©ment ‚Üí `[]`
- Bloc non applicable ‚Üí `"applicable": false`
- Section non trait√©e par la CC ‚Üí `"statut": "non_traite"`
""".strip()


class ReformulationService:
    """Service pour reformuler les conventions avec 2 IA en parall√®le"""
    
    def __init__(self):
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
        
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found in environment")
        if not self.deepseek_api_key:
            raise ValueError("DEEPSEEK_API_KEY not found in environment")
        
        # Init Gemini
        genai.configure(api_key=self.gemini_api_key)
        self.gemini_model = genai.GenerativeModel(
            "gemini-2.5-flash",
            generation_config={"temperature": TEMPERATURE}
        )
        
        logger.info("ReformulationService initialized")
    
    def clean_html(self, raw_html: str) -> str:
        """Nettoie le HTML (logique identique script original)"""
        if not raw_html:
            return ""
        
        cleaned = raw_html
        cleaned = re.sub(r'<script[^>]*>.*?</script>', '', cleaned, flags=re.DOTALL)
        cleaned = re.sub(r'try\s*\{[^}]*\$\([^}]*\}[^}]*\}[^}]*catch\s*\([^)]*\)\s*\{\s*\}', '', cleaned, flags=re.DOTALL)
        cleaned = re.sub(r'<!--.*?-->', '', cleaned, flags=re.DOTALL)
        cleaned = re.sub(r'\s+(style|width|height|valign|align|border|cellpadding|cellspacing|id|name|src|alt|title)="[^"]*"', '', cleaned)
        cleaned = re.sub(r'\s+(ng-[a-z-]+|data-[a-z-]+|on\w+)="[^"]*"', '', cleaned)
        cleaned = re.sub(r'<table[^>]*class="contactredac-table"[^>]*>.*?</table>', '', cleaned, flags=re.DOTALL)
        cleaned = re.sub(r'<img[^>]*/?>', '', cleaned)
        cleaned = re.sub(r'<a[^>]*>\s*</a>', '', cleaned)
        cleaned = re.sub(r'\n\s*\n+', '\n', cleaned)
        cleaned = re.sub(r'  +', ' ', cleaned)
        
        return cleaned.strip()
    
    def load_prompt(self, section: str) -> str:
        """Charge le prompt d'une section"""
        prompt_file = PROMPTS_DIR / f"{section}.md"
        
        if not prompt_file.exists():
            raise FileNotFoundError(f"Prompt file not found: {prompt_file}")
        
        return prompt_file.read_text(encoding='utf-8')
    
    async def call_gemini(self, prompt: str, content: str) -> Optional[Dict]:
        """Appelle Gemini AI"""
        try:
            full_prompt = f"{SYSTEM_PROMPT}\n\n{prompt}\n\n## CONTENU √Ä ANALYSER\n\n{content}"
            
            response = self.gemini_model.generate_content(full_prompt)
            response_text = response.text.strip()
            
            # Retirer markdown si pr√©sent
            if response_text.startswith("```"):
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            
            return json.loads(response_text)
        
        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            return None
    
    async def call_deepseek(self, prompt: str, content: str) -> Optional[Dict]:
        """Appelle DeepSeek AI"""
        try:
            full_prompt = f"{SYSTEM_PROMPT}\n\n{prompt}\n\n## CONTENU √Ä ANALYSER\n\n{content}"
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    "https://api.deepseek.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.deepseek_api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "deepseek-chat",
                        "messages": [
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": f"{prompt}\n\n## CONTENU √Ä ANALYSER\n\n{content}"}
                        ],
                        "temperature": TEMPERATURE
                    }
                )
                
                if response.status_code != 200:
                    logger.error(f"DeepSeek API error: {response.status_code} - {response.text}")
                    return None
                
                result = response.json()
                response_text = result['choices'][0]['message']['content'].strip()
                
                # Retirer markdown si pr√©sent
                if response_text.startswith("```"):
                    response_text = response_text.split("```json")[1].split("```")[0].strip()
                
                return json.loads(response_text)
        
        except Exception as e:
            logger.error(f"DeepSeek API error: {e}")
            return None
    
    async def reformulate_convention(self, raw_html: str, status_callback=None) -> Dict[str, Dict]:
        """
        Reformule une convention avec les 2 IA en parall√®le
        
        Returns:
            {
                "gemini": {...},
                "deepseek": {...}
            }
        """
        content = self.clean_html(raw_html)
        
        if not content:
            raise ValueError("No content to reformulate")
        
        results_gemini = {}
        results_deepseek = {}
        
        # Pour chaque section
        total_sections = len(SECTIONS)
        for i, section in enumerate(SECTIONS):
            logger.info(f"Processing section: {section}")
            
            if status_callback:
                status_callback(section, i + 1, total_sections)
            
            try:
                # Charger le prompt
                prompt = self.load_prompt(section)
                
                # Appeler les 2 IA en PARALL√àLE
                gemini_task = self.call_gemini(prompt, content)
                deepseek_task = self.call_deepseek(prompt, content)
                
                results_list = await asyncio.gather(gemini_task, deepseek_task, return_exceptions=True)
                
                gemini_result, deepseek_result = results_list
                
                # Check Gemini result
                if isinstance(gemini_result, Exception):
                    logger.error(f"Gemini error for section {section}: {gemini_result}")
                elif gemini_result:
                    results_gemini[section] = gemini_result
                
                # Check DeepSeek result
                if isinstance(deepseek_result, Exception):
                    logger.error(f"DeepSeek error for section {section}: {deepseek_result}")
                elif deepseek_result:
                    results_deepseek[section] = deepseek_result
                
                # Petit d√©lai pour √©viter rate limits m√™me en parall√®le
                await asyncio.sleep(API_DELAY)
            
            except Exception as e:
                logger.error(f"Error processing section {section}: {e}")
                continue
        
        return {
            "gemini": results_gemini,
            "deepseek": results_deepseek
        }
